# Simultaneous Machine Translation with Adapters (SiMT_NLP)

A PyTorch implementation of fixed and adaptive simultaneous machine translation strategies using adapter modules, based on the paper ["Fixed and Adaptive Simultaneous Machine Translation Strategies Using Adapters"](https://arxiv.org/abs/XXXX.XXXX).

## Table of Contents
- [Features](#features)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Usage](#usage)
- [Configuration](#configuration)
- [Testing](#testing)
- [Acknowledgments](#acknowledgments)

## Features
- ğŸš€ Transformer model with lightweight adapter modules
- â±ï¸ Two inference strategies:
  - Fixed wait-k policy
  - Adaptive threshold-based strategy
- ğŸ”„ Multi-path training with parameter sharing
- ğŸ“Š Latency-quality tradeoff management
- ğŸ’¾ Checkpoint averaging and management

## Installation
1. Clone the repository:
```bash
git clone https://github.com/yourusername/SiMT_NLP.git
cd SiMT_NLP

pip install -r requirements.txt

SiMT_NLP/
â”‚
â”œâ”€â”€ adapters.py          # Adapter module implementation for Transformer
â”œâ”€â”€ model.py             # Transformer model with adapter integration
â”œâ”€â”€ utils.py             # Utility functions (padding, tokenization, etc.)
â”œâ”€â”€ dataset.py           # Dataset loading and preprocessing
â”œâ”€â”€ train.py             # Training script with checkpoint management
â”œâ”€â”€ fixed_inference.py   # Fixed wait-k inference implementation (Algorithm 1 from paper)
â”œâ”€â”€ adaptive_inference.py# Adaptive inference (Algorithm 2 from paper)
â”œâ”€â”€ config.py            # Configuration settings (hyperparameters & enums)
â”œâ”€â”€ test.py              # Interactive translation interface
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ run.sh               # Training automation script
â””â”€â”€ README.md            # Project documentation

./run.sh